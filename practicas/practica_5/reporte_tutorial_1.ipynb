{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reporte_tutorial_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikmAcX_1M_Sr"
      },
      "source": [
        "### Reporte Practica 5 - Tutorial 1\n",
        "### Autor: Javier Abarca Jimenez \n",
        "### Carné: B70018\n",
        "### Tutorial: [Your First Deep Learning Project in Python with Keras Step-By-Step](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HolV85VcNnhv"
      },
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oBBINqVM_Gd"
      },
      "source": [
        "# first neural network with keras tutorial\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH3WPGJ8Nf7v"
      },
      "source": [
        "# load the dataset\n",
        "dataset = loadtxt(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\", delimiter=',')\n",
        "# split into input (X) and output (y) variables\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnMdNSx1N0SD"
      },
      "source": [
        "## 2. Define Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8YaOR3GONdp"
      },
      "source": [
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz02-2tgOYV6"
      },
      "source": [
        "## 3. Compile Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTxV6TGgOc2n"
      },
      "source": [
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyoqfEtqOgCK"
      },
      "source": [
        "## 4. Fit Keras Model\n",
        "* Epoch: Una pasada a través de todas las filas del conjunto de datos de entrenamiento.\n",
        "* Batch: Una o más muestras consideradas por el modelo dentro de una época antes de que se actualicen los pesos.\n",
        "\n",
        "Un epoch se compone de uno o más batches, según el tamaño de batch elegido y el modelo es apto para muchas epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTWtFMgNPB3T",
        "outputId": "cd100b32-856b-4d8f-9411-8347e21f3aad"
      },
      "source": [
        "# fit the keras model on the dataset\n",
        "model.fit(X, y, epochs=150, batch_size=10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "77/77 [==============================] - 1s 1ms/step - loss: 2.8300 - accuracy: 0.5703\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.8390 - accuracy: 0.6771\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.7009 - accuracy: 0.6823\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6697 - accuracy: 0.6849\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6466 - accuracy: 0.6784\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6458 - accuracy: 0.6797\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6311 - accuracy: 0.6927\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6209 - accuracy: 0.6992\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6223 - accuracy: 0.6875\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6115 - accuracy: 0.7083\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6063 - accuracy: 0.7070\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6119 - accuracy: 0.6940\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6122 - accuracy: 0.6914\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6004 - accuracy: 0.7057\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.6966\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.6875\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5944 - accuracy: 0.7070\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6047 - accuracy: 0.6979\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5988 - accuracy: 0.7096\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5950 - accuracy: 0.7044\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6016 - accuracy: 0.7174\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5934 - accuracy: 0.7005\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5950 - accuracy: 0.7044\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5837 - accuracy: 0.7109\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5797 - accuracy: 0.7279\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5851 - accuracy: 0.7070\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7083\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5717 - accuracy: 0.7148\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5856 - accuracy: 0.7031\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5870 - accuracy: 0.7279\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5859 - accuracy: 0.6992\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5723 - accuracy: 0.7188\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5600 - accuracy: 0.7188\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5752 - accuracy: 0.7122\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5665 - accuracy: 0.7122\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5754 - accuracy: 0.7174\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5727 - accuracy: 0.7253\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5695 - accuracy: 0.7174\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7188\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5621 - accuracy: 0.7253\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7240\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5667 - accuracy: 0.7292\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5490 - accuracy: 0.7227\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5703 - accuracy: 0.7135\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5496 - accuracy: 0.7292\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7370\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7122\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5438 - accuracy: 0.7357\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5449 - accuracy: 0.7422\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5479 - accuracy: 0.7305\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.7292\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.7370\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5438 - accuracy: 0.7331\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5375 - accuracy: 0.7435\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5451 - accuracy: 0.7318\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5408 - accuracy: 0.7396\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5407 - accuracy: 0.7383\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5344 - accuracy: 0.7331\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5402 - accuracy: 0.7370\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5361 - accuracy: 0.7331\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5350 - accuracy: 0.7318\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5368 - accuracy: 0.7474\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5395 - accuracy: 0.7435\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7500\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5337 - accuracy: 0.7474\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5401 - accuracy: 0.7344\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5411 - accuracy: 0.7279\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5359 - accuracy: 0.7370\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5331 - accuracy: 0.7448\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5401 - accuracy: 0.7435\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5599 - accuracy: 0.7214\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5276 - accuracy: 0.7474\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5297 - accuracy: 0.7344\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.7448\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7318\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5259 - accuracy: 0.7422\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5287 - accuracy: 0.7422\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5367 - accuracy: 0.7370\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5222 - accuracy: 0.7448\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5384 - accuracy: 0.7383\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5306 - accuracy: 0.7396\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5148 - accuracy: 0.7461\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5228 - accuracy: 0.7422\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5208 - accuracy: 0.7383\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5214 - accuracy: 0.7539\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5081 - accuracy: 0.7539\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5328 - accuracy: 0.7396\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5173 - accuracy: 0.7305\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5212 - accuracy: 0.7513\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5233 - accuracy: 0.7266\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5176 - accuracy: 0.7448\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5279 - accuracy: 0.7591\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5157 - accuracy: 0.7487\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5086 - accuracy: 0.7474\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5223 - accuracy: 0.7487\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7331\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5220 - accuracy: 0.7487\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5250 - accuracy: 0.7409\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5038 - accuracy: 0.7513\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5057 - accuracy: 0.7565\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5110 - accuracy: 0.7422\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5060 - accuracy: 0.7552\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5154 - accuracy: 0.7513\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5090 - accuracy: 0.7513\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5293 - accuracy: 0.7487\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5091 - accuracy: 0.7604\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.7604\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5090 - accuracy: 0.7552\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5099 - accuracy: 0.7448\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5126 - accuracy: 0.7448\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.7409\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5034 - accuracy: 0.7513\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5119 - accuracy: 0.7461\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7435\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.7526\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5103 - accuracy: 0.7539\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7448\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7487\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4979 - accuracy: 0.7513\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4937 - accuracy: 0.7578\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5039 - accuracy: 0.7461\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7513\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.7565\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4994 - accuracy: 0.7487\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.7539\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4941 - accuracy: 0.7565\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4905 - accuracy: 0.7552\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.7513\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.7565\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4984 - accuracy: 0.7643\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.7565\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.7448\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4894 - accuracy: 0.7461\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.7565\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.7630\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4871 - accuracy: 0.7461\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7539\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4991 - accuracy: 0.7565\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7552\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7708\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7656\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.7578\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.7526\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4918 - accuracy: 0.7539\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7578\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7630\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7552\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4945 - accuracy: 0.7682\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7526\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.4921 - accuracy: 0.7539\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc08be476d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUXeDsvKPSay"
      },
      "source": [
        "## 5. Evaluate Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn5mqCokPcNX",
        "outputId": "47978457-aa17-42fa-de8c-eaa6dad1e714"
      },
      "source": [
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7604\n",
            "Accuracy: 76.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyB5VhQOPezm"
      },
      "source": [
        "## 6. Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68nomdiCQC4D",
        "outputId": "a16da2b3-3584-4559-cd4c-d9e5493288f3"
      },
      "source": [
        "# make class predictions with the model\n",
        "predictions = (model.predict(X) > 0.5).astype(int)\n",
        "# summarize the first 5 cases\n",
        "for i in range(5):\n",
        "\tprint('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 1 (expected 1)\n",
            "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
            "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 1 (expected 1)\n",
            "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
            "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 1 (expected 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "volya-9sQbrb"
      },
      "source": [
        "## Comentarios\n",
        "Sirvió para repasar conceptos y funciones, por lo que quedó todo claro por el momento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUKi3mD7RMrl"
      },
      "source": [
        "## Reporte\n",
        "### Resumen\n",
        "En este tutorial se vieron una serie de pasos utilizando la librería de Python Keras para aprendizaje profundo. Estos pasos cubrieron la implementación necesaria para lo siguiente:\n",
        "* Definición de una red neuronal.\n",
        "* Compilación de un modelo.\n",
        "* Entrenamiento del modelo utilizando los datos.\n",
        "* Evaluación del modelo.\n",
        "* Predicciones utilizando el modelo entrenado.\n",
        " \n",
        "### Comentarios\n",
        "La decisiones tomadas para decidir funciones de activación fue muy útil verlas aplicadas posteriormente de haber hecho los otros reportes y con la explicación de este propio tutorial.\n",
        " \n",
        "### Dudas\n",
        "Por ahora no tengo dudas.\n"
      ]
    }
  ]
}